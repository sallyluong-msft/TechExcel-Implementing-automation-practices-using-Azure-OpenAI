---
title: '3. Check for audio call compliance'
layout: default
nav_order: 3
parent: 'Exercise 05: Provide live audio transcription'
---

# Task 03 - Check for audio call compliance (30 minutes)

## Introduction

So far in this exercise, we have focused on generating transcripts from audio, either in pre-existing files or live calls. This task will build upon the work in the prior two, allowing Contoso Suites to analyze calls and generate automated insights. You will build a simple compliance checker with three simple rules:

1. Does the call contain vulgarity?
2. If the call needs an indicator that Contoso Suites is recording it, did that indicator happen? An example of this is when you hear the message "This call may be monitored or recorded for quality assurance and training purposes" on telephone calls.
3. If users wish to check whether a call is actually relevant to Contoso Suites, was the call relevant? Contoso Suites deals with the hotel and travel industry.

## Description

In this task, you will fill in functionality to perform call compliance checks. This call compliance should work either from transcribed audio files or transcribed chat lines in a live call.

The key tasks are as follows:

1. In the Streamlit dashboard, open the page `2_Call_Center.py`. Navigate to the `main()` function and into the "Is Your Call in Compliance?" section. Implement the TODO items to fill out the function call.
2. Implement the TODO items in the `is_call_in_compliance()` function to complete this function.
3. Implement the TODO items in the `make_azure_openai_chat_request()` function to complete this function.
4. Either upload the file `01_Customer_Call.wav` or perform a live call. After transcription completes and the results are in Streamlit's session state, check the boxes for **Call needs an indicator we are recording it** and **Call is relevant to the hotel and resort industry**. Based on the transcription, ensure that the results make sense.
5. Upload the file `02_Customer_Call_Bad.wav`. Read the transcript to determine if there was an indicator of recording and if the call is relevant. Check the boxes for **Call needs an indicator we are recording it** and **Call is relevant to the hotel and resort industry** and run the compliance check.
6. Upload the file `02b_Customer_Call_Bad_Wrong_Sample_Rate.wav`. This is the same as the prior recording except at a sample rate of 44100 Hz whereas we expect 16000 Hz. Read the transcript to see what happens when we process a file using the wrong sample rate. Check the boxes for **Call needs an indicator we are recording it** and **Call is relevant to the hotel and resort industry** and run the compliance check.

## Success Criteria

- You have completed the `is_call_in_compliance()` and `make_azure_openai_chat_request()` functions.
- You are able to perform a compliance check on audio inputs, whether from file or live recording.

## Learning Resources

- [Quickstart: Get started using GPT-35-Turbo and GPT-4 with Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line%2Cpython&pivots=programming-language-python)
- [st.spinner](https://docs.streamlit.io/library/api-reference/status/st.spinner)
- [st.success](https://docs.streamlit.io/library/api-reference/status/st.success)
- [Streamlit Session State](https://docs.streamlit.io/library/api-reference/session-state)

## Solution

<details markdown="block">
<summary>Expand this section to view the solution</summary>

- The code to implement the "Is Your Call in Compliance?" section in the `main()` function is as follows:

    ```python
    include_recording_message = st.checkbox("Call needs an indicator we are recording it")
    is_relevant_to_topic = st.checkbox("Call is relevant to the hotel and resort industry")

    if st.button("Check for Compliance"):
        with st.spinner("Checking for compliance..."):
            if 'file_transcription_results' in st.session_state:
                call_contents = st.session_state.file_transcription_results
            elif 'transcription_results' in st.session_state:
                call_contents = st.session_state.transcription_results
            else:
                st.write("Please upload an audio file or record a call before checking for compliance.")
            if call_contents is not None and len(call_contents) > 0:
                compliance_results = is_call_in_compliance(call_contents, include_recording_message, is_relevant_to_topic)
                st.write(compliance_results)
        st.success("Compliance check complete!")
    ```

- The `is_call_in_compliance()` function converts the list of transcription strings into a single message. Then, based on whether the user has checked either (or both) of the two boxes, it builds out prompt template addenda for the system prompt. It then calls `make_azure_openai_chat_request()` with that prompt and the call contents message.
  - The code for the completed `is_call_in_compliance()` function is as follows:

    ```python
    joined_call_contents = ' '.join(call_contents)
    if include_recording_message:
        include_recording_message_text = "2. Was the caller aware that the call was being recorded?"
    else:
        include_recording_message_text = ""

    if is_relevant_to_topic:
        is_relevant_to_topic_text = "3. Was the call relevant to the hotel and resort industry?"
    else:
        is_relevant_to_topic_text = ""

    system = f"""
        You are an automated analysis system for Contoso Suites. Contoso Suites is a luxury hotel and resort chain with locations
        in a variety of Caribbean nations and territories.
        
        You are analyzing a call for relevance and compliance.

        You will only answer the following questions based on the call contents:
        1. Was there vulgarity on the call?
        {include_recording_message_text}
        {is_relevant_to_topic_text}
    """

    response = make_azure_openai_chat_request(system, joined_call_contents)
    return response.choices[0].message.content
    ```

- The `make_azure_openai_chat_request()` function connects to the Azure OpenAI client and builds a chat completion containing two messages: a system message telling the GPT deployment about its role, and a user message with the transcribed audio contents.
  - The code for the completed `make_azure_openai_chat_request()` function is as follows:

    ```python
    # Create an Azure OpenAI client.
    client = openai.AzureOpenAI(
        base_url=f"{aoai_endpoint}/openai/deployments/{deployment_name}/",
        api_key=aoai_api_key,
        api_version="2023-12-01-preview"
    )

    # Create and return a new chat completion request
    return client.chat.completions.create(
        model=deployment_name,
        messages=[
            {"role": "system", "content": system},
            {"role": "user", "content": call_contents}
        ],
    )
    ```

</details>
